{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a37c646-3b27-445c-9089-26f41fdd186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_wiki.csv\t     de_wiki_cleaned_sentences.txt  petite.csv\n",
      "de_wiki_cleaned.csv  dewiki.txt\n"
     ]
    }
   ],
   "source": [
    "# traing data into this folder\n",
    "!ls /veld/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dab2ed-1791-4cb8-9fa2-7480f2f41b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.ipynb  train.ipynb\n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "!ls /veld/executable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4ab13e-0705-4f47-9d90-faf367fb823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1  m2\tm3  m4\n"
     ]
    }
   ],
   "source": [
    "# save models here\n",
    "!ls /veld/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9aa7c-7e37-40bf-9291-36a0c5c92a2d",
   "metadata": {},
   "source": [
    "New approach 20240426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90643c2a-fa98-43bc-8edb-e64bdc263ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3204425d-90e2-4ee7-b027-2d828a99b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "petite= pd.read_csv(\"/veld/input/de_wiki.csv\")\n",
    "petite = petite.rename(columns={\"\\ttext\": \"text\"})\n",
    "\n",
    "petite_cleaned = petite.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379fb40a-6377-46e5-9f12-08ebd4a9ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(petite)):\n",
    "    text = petite.iloc[i][\"text\"]\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\t\", \"\", text)\n",
    "    text = re.sub(r\"“\", \"\", text)\n",
    "    text = re.sub(r\"„\", \"\", text)\n",
    "    petite_cleaned.iloc[i][\"text\"] = text #we load the data from the left into the variety to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c859a0-928b-4bf2-81a5-c18e6dc552ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\tAlan Smithee steht als Pseudonym für einen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1\\tActinium ist ein radioaktives chemisches El...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2\\tAng Lee Oktober in Chaozhou Landkreis Pingt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3\\tAnschluss ist in der Soziologie ein Fachbeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4\\tDie Aussagenlogik ist ein Teilgebiet der Lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  0\\tAlan Smithee steht als Pseudonym für einen ...\n",
       "1  1\\tActinium ist ein radioaktives chemisches El...\n",
       "2  2\\tAng Lee Oktober in Chaozhou Landkreis Pingt...\n",
       "3  3\\tAnschluss ist in der Soziologie ein Fachbeg...\n",
       "4  4\\tDie Aussagenlogik ist ein Teilgebiet der Lo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf35287-9b5e-4212-9447-ae6e645effa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Smithee steht als Pseudonym für einen fik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actinium ist ein radioaktives chemisches Eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ang Lee Oktober in Chaozhou Landkreis Pingtung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anschluss ist in der Soziologie ein Fachbegrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Aussagenlogik ist ein Teilgebiet der Logik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Alan Smithee steht als Pseudonym für einen fik...\n",
       "1  Actinium ist ein radioaktives chemisches Eleme...\n",
       "2  Ang Lee Oktober in Chaozhou Landkreis Pingtung...\n",
       "3  Anschluss ist in der Soziologie ein Fachbegrif...\n",
       "4  Die Aussagenlogik ist ein Teilgebiet der Logik..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petite_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec233ce1-9b1c-4179-9198-0f82345afb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>435473</th>\n",
       "      <td>Das Kastell Würzberg in der älteren Literatur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291377</th>\n",
       "      <td>Robert Kurt Kudielka August in Lindau Bodensee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152320</th>\n",
       "      <td>Uebigau Wahrenbrück ist eine Stadt im Landkrei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448715</th>\n",
       "      <td>Ken Leung Januar in New York City ist ein US a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416056</th>\n",
       "      <td>Juliette ist ein französischer weiblicher Vorn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "435473  Das Kastell Würzberg in der älteren Literatur ...\n",
       "291377  Robert Kurt Kudielka August in Lindau Bodensee...\n",
       "152320  Uebigau Wahrenbrück ist eine Stadt im Landkrei...\n",
       "448715  Ken Leung Januar in New York City ist ein US a...\n",
       "416056  Juliette ist ein französischer weiblicher Vorn..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petite_cleaned.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a763fd3-3bed-490c-ac68-4860ece2102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/veld/output/clean/de_wiki_cleaned.csv\"\n",
    "MODEL_PATH = \"/veld/output/model/20240426word2vec_de.model\"\n",
    "MODEL_METADATA_PATH = \"/veld/output/model/metadata.yaml\"\n",
    "TRAIN_DATA_NAME = \"german wikipedia, csv\"\n",
    "VECTOR_SIZE = 200\n",
    "WINDOW = 3\n",
    "MIN_COUNT = 1\n",
    "WORKERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eab40d3-040d-4bbb-bb28-824036e8cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "petite_cleaned.to_csv(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a360935a-4f3f-4368-a008-fcb47be9ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e03550-1f27-4ff5-becd-2c75cff02614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterable:\n",
    "\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for line in self.df.iterrows():\n",
    "            yield simple_preprocess(line[1][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7272a96-5ca2-4666-95e5-8ddd6a438ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = Iterable(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688a1248-0c61-4d35-b039-beb783af984c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWord2Vec\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVECTOR_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWINDOW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_COUNT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWORKERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m time_end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m      8\u001b[0m duration \u001b[38;5;241m=\u001b[39m (time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m.\u001b[39mseconds \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gensim/models/word2vec.py:429\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m    431\u001b[0m         corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count,\n\u001b[1;32m    432\u001b[0m         total_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m    433\u001b[0m         end_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha, compute_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gensim/models/word2vec.py:491\u001b[0m, in \u001b[0;36mWord2Vec.build_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build vocabulary from a sequence of sentences (can be a once-only generator stream).\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 491\u001b[0m total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_vocab\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_per\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_per\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count \u001b[38;5;241m=\u001b[39m corpus_count\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m total_words\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gensim/models/word2vec.py:586\u001b[0m, in \u001b[0;36mWord2Vec.scan_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_file:\n\u001b[1;32m    584\u001b[0m     corpus_iterable \u001b[38;5;241m=\u001b[39m LineSentence(corpus_file)\n\u001b[0;32m--> 586\u001b[0m total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_per\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollected \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m word types from a corpus of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m raw words and \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_vocab), total_words, corpus_count\n\u001b[1;32m    591\u001b[0m )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_words, corpus_count\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gensim/models/word2vec.py:555\u001b[0m, in \u001b[0;36mWord2Vec._scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    553\u001b[0m vocab \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    554\u001b[0m checked_string_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence_no, sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentences):\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checked_string_types:\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sentence, \u001b[38;5;28mstr\u001b[39m):\n",
      "Cell \u001b[0;32mIn[35], line 8\u001b[0m, in \u001b[0;36mIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43msimple_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gensim/utils.py:310\u001b[0m, in \u001b[0;36msimple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_preprocess\u001b[39m(doc, deacc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    Uses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    311\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenize(doc, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, deacc\u001b[38;5;241m=\u001b[39mdeacc, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m min_len \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_len \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    313\u001b[0m     ]\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gensim/utils.py:312\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_preprocess\u001b[39m(doc, deacc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    Uses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    311\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenize(doc, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, deacc\u001b[38;5;241m=\u001b[39mdeacc, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m min_len \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_len \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    313\u001b[0m     ]\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "model = gensim.models.Word2Vec (iter,\n",
    "                                vector_size=VECTOR_SIZE,\n",
    "                                window=WINDOW,\n",
    "                                min_count=MIN_COUNT,\n",
    "                                workers=WORKERS)\n",
    "time_end = datetime.now()\n",
    "duration = (time_end - time_start).seconds / 60\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803f469-a7c8-4869-b052-c7e1a74afc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# calculate size of training data\n",
    "def calc_size(file):\n",
    "    size = os.path.getsize(file)\n",
    "    for unit in [\"\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if abs(size) < 1024.0:\n",
    "            return f\"{round(size, 1)} {unit}\"\n",
    "        size /= 1024.0\n",
    "train_data_size = calc_size(TRAIN_DATA_PATH)\n",
    "model_data_size = calc_size(MODEL_PATH)\n",
    "\n",
    "# calculate hash of training data\n",
    "train_data_md5_hash = subprocess.run([\"md5sum\", TRAIN_DATA_PATH], capture_output=True, text=True)\n",
    "train_data_md5_hash = train_data_md5_hash.stdout.split()[0]\n",
    "\n",
    "\n",
    "# aggregate into metadata dictionary\n",
    "metadata = {\n",
    "    \"train_data_name\": TRAIN_DATA_NAME,\n",
    "    \"train_data_size\": train_data_size,\n",
    "    \"train_data_md5_hash\": train_data_md5_hash,\n",
    "    \"training_vector_size\": VECTOR_SIZE,\n",
    "    \"window\": WINDOW,\n",
    "    \"min_count\": MIN_COUNT,\n",
    "    \"workers\": WORKERS,\n",
    "    \"training_duration (minutes)\": round(duration, 1),\n",
    "    \"model_data_size\": model_data_size,\n",
    "}\n",
    "\n",
    "# write to yaml\n",
    "with open(MODEL_METADATA_PATH, \"w\") as f:\n",
    "    # iteration over dictionary to ensure the yaml writer respects the order\n",
    "    for k, v in metadata.items():\n",
    "        yaml.dump({k: v}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9642ef3-e17e-4f9f-b71c-beff2b26101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word =\"Wien\"\n",
    "print(f'Similaries to {word}:')\n",
    "for similar_word, similarity in model.wv.most_similar(word, topn=10):\n",
    "    print(f\"- {similar_word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3304a19-bc08-400b-95bb-9070219faa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word =\"Frau\"\n",
    "print(f'Similaries to {word}:')\n",
    "for similar_word, similarity in model.wv.most_similar(word, topn=10):\n",
    "    print(f\"- {similar_word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe24a7-ab50-4a15-82d1-e53c8e0cefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "word =\"Dame\"\n",
    "print(f'Similaries to {word}:')\n",
    "for similar_word, similarity in model.wv.most_similar(word, topn=10):\n",
    "    print(f\"- {similar_word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0089f52-e482-4ace-bc5d-7f437b95e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word =\"Baum\"\n",
    "print(f'Similaries to {word}:')\n",
    "for similar_word, similarity in model.wv.most_similar(word, topn=10):\n",
    "    print(f\"- {similar_word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f44d36-b1c2-4da2-8b95-bf70f2272833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('Frau', 'Dame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ca867-bd5c-43f5-b822-d7162be4f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['Frau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b49e2-5c01-4a3d-9561-0e6195235412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d44958-06d2-4529-a854-8b0193f164ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd91b1-650a-4f3e-a5cb-a145a2a52e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('Frau', 'Baum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819711f8-2baa-4e2c-bee7-2e7371034820",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('Dame', 'Baum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3536a1a-ce3f-4afa-ac87-ebf64a0773da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between two word vectors\n",
    "def cosine_similarity(word1, word2):\n",
    "    try:\n",
    "        # Calculate cosine similarity between the word vectors\n",
    "        similarity_score = model.wv.similarity(word1, word2)\n",
    "        return similarity_score\n",
    "    except KeyError:\n",
    "        # Handle the case where one or both words are not in the vocabulary\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "word1 = 'Frau'\n",
    "word2 = 'Dame'\n",
    "\n",
    "# Calculate cosine similarity between 'Frau' and 'Dame'\n",
    "similarity_score = cosine_similarity(word1, word2)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word1}' and '{word2}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word1}' or '{word2}' is not in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf23e8-e8fd-4527-ba05-b37bcc10ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word3 = 'Ball'\n",
    "word4 = 'Fest'\n",
    "\n",
    "# Calculate cosine similarity between 'Ball' and 'Fest'\n",
    "similarity_score = cosine_similarity(word3, word4)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word3}' and '{word4}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word3}' or '{word4}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a973377-1962-43a1-9ae1-1688771801c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word5 = 'Gala'\n",
    "word6 = 'Fest'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word5, word6)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word5}' and '{word6}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word5}' or '{word6}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51fc16-a866-4908-91c6-a6fedc72a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word7 = 'Tanz'\n",
    "word8 = 'Fest'\n",
    "\n",
    "# Calculate cosine similarity between 'Tanz' and 'Fest'\n",
    "similarity_score = cosine_similarity(word7, word8)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word7}' and '{word8}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word7}' or '{word8}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b04bea-ad50-43e7-872e-e823acd6783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word9 = 'Gala'\n",
    "word10 = 'Tanz'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word9, word10)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word9}' and '{word10}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word9}' or '{word10}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696caf4d-9343-4d23-ac66-2ceee7f61da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word11 = 'Ball'\n",
    "word12 = 'Tanz'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word11, word12)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word11}' and '{word12}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word11}' or '{word12}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb8f80-a53a-470f-be38-ccc7575c08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word13 = 'Ball'\n",
    "word14 = 'Gala'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word13, word14)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word13}' and '{word14}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word13}' or '{word14}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87de37-2820-4747-a61c-674577df6350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word15 = 'Zweck'\n",
    "word16 = 'Ziel'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word15, word16)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word15}' and '{word16}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word15}' or '{word16}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cce271-7901-4e7c-9ab5-36ab26a60907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word17 = 'Feuer'\n",
    "word18 = 'Brand'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word17, word18)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word17}' and '{word18}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word17}' or '{word18}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc693a5-f32e-4a5a-858b-254c186126dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word19 = 'Haltestelle'\n",
    "word20 = 'Station'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word19, word20)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word19}' and '{word20}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word19}' or '{word20}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1aef0-4a08-4147-acd3-68cc09e64695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word21 = 'Zahl'\n",
    "word22 = 'Nummer'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word21, word22)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word21}' and '{word22}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word21}' or '{word22}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb79677-1ba3-4da5-9cf9-0b41ae89a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word25 = 'Raum'\n",
    "word26 = 'Zimmer'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word25, word26)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word25}' and '{word26}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word25}' or '{word26}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5056cd-3506-4405-87d6-ec9e418e842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word27 = 'Etage'\n",
    "word28 = 'Stock'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word27, word28)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word27}' and '{word28}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word27}' or '{word28}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670d13e-7fb9-4e0d-94f1-3ef980961efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word27 = 'Ball'\n",
    "word28 = 'Kugel'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word27, word28)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word27}' and '{word28}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word27}' or '{word28}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418cb55-7c91-4d2d-be32-385c8850fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word27 = 'Frau'\n",
    "word28 = 'Mann'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word27, word28)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word27}' and '{word28}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word27}' or '{word28}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f73dc-4233-4a10-ad3d-3f31e1296c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "word27 = 'Frau'\n",
    "word28 = 'Dame'\n",
    "\n",
    "# Calculate cosine similarity between 'Gala' and 'Fest'\n",
    "similarity_score = cosine_similarity(word27, word28)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Cosine Similarity between '{word27}' and '{word28}': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(f\"At least one of the words '{word27}' or '{word28}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9df46-45f7-4a20-98d2-a23f83c844f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353d6c5-e01e-4af5-83e5-da67334cb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"/veld/output/model/20240425word2vec_de.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463d885-5303-4589-bf31-949a640981e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('Frau', 'Dame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d579706-2825-4dfc-9470-a93b06adbd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
